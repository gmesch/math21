<!doctype html>
<html>
  <head>
    <title>Math for ML</title>
    
    <script src="lib/jslib.js"></script>    
    <script src="lib/state.js"></script>
    <script src="lib/state_util.js"></script>
    <script src="lib/slides.js"></script>

    <link href="lib/slides.css" rel="stylesheet">    
    <link href="slides_style.css" rel="stylesheet">

    <script src="slides_mathjax.js"></script>
    <script src="slides_loader.js"></script>
    <script src="prettify/run_prettify.js?autorun=false&lang=scm" async></script>

    <script src="lib/firebase.js"></script>
    <script src="lib/canvas.js"></script>
    <script src="slides_init.js"></script>
  </head>

  <body onload="init()">
    
    <div id="bgpage" class="background">
      <canvas id="canvas"></canvas>
    </div>
    
    <div class="header">
    </div>

    <div id="footer" class="footer">
      <div id="navigator" class="large"></div>
    </div>

    <div id="slides" class="slides">
      <div class="slide title"
           onshow="d0('navigator','footer');v0('bgpage')"
           onhide="d1('navigator','footer');v1('bgpage')">

        <h1>Linear Algebra for Machine Learning</h1>
        <h2>Tai-Danae, Mesch</h2>
        
        <div class="bottom">
          <h2 class="venue">X/Google, 2021</h2>
        </div>
      </div>
      
      <div class="slide build-focus-visible" group="intro" name="intro">
        <h1>Intro: Tensors!</h1>
        <div>The ML library we all use is called
          Tensorflow, after those things from Linear Algebra. But
          what <em>are</em> Tensors really?</div>
        <div>Important, is what they are!</div>
        <ul>
          <li step="1">In <b>General Relativity</b>, tensors describe
            Gravitation.
            
          <li step="2">In <b>Quantum Mechanics</b>, multi-particle states are
            the tensor products of single particle states.

          <li step="3">In <b>Quantum Computing</b>, each qubit is one factor of
            a tensor product.

          <li step="4">In <b>Machine Learning</b> ... well, those "tensors" in
            Tensorflow are just superficially connected with what they are in
            Mathematics -- we'll explain how exactly! -- but tensor products
            appear in interesting places when optimizing weight matrices in
            large models.
        </ul>

        <div class="notes">Remember to look at the notes.</div>
      </div>

      <div class="slide build-focus-visible" group="intro" name="plan">
        <h1>Game Plan</h1>
        <div>Throughout the next 3 sessions:</div>

        <ul>
          <li step="1" link="theme1">We explain what tensors are, and how the
            name became associated with multidimensional array data structures
            in software engineering, especially in machine learning.
            
          <li step="2" link="theme2">We contemplate how tensor products of
            vector spaces have a peculiar scaling behavior in their dimension:
            Unlike the Cartesian Product, which adds the dimensions of its
            factors, the Tensor Product multiplies. We also contemplate how
            confusing it is that

            $$ 2 + 2 = 2 \times 2 = 2^2 $$

            and what happens when we go beyond 2.

          <li step="3" link="theme3">We finally look again how tensors and their
            products appear in machine learning models.
        </ul>
      </div>

      <div class="slide build-focus-visible" group="intro">
        <h1>Meta</h1>

        <div>Besides the improved understanding of ML and QC, there are a few
          tangential motivations that are inspiring in their own right, or for
          building software:</div>

        <ul>
          <li step="1">Understand better axiomatic construction.

          <li step="2">Introduce more Notation.

          <li step="3">Revisit learnings from new perspectives. (Remember the
            Tensorflow code retreat.)

          <li step="4">Introduce important mathematical concepts, such as
            Isomorphism and Duality.
        </ul>
      </div>

      <div class="slide build-focus-visible" group="intro">
        <h1>How to follow along</h1>

        <div>How to use these slides:</div>

        <ul>
          <li step="1">Find them
            at <a href="https://gmesch.github.io/math21/slides.html">gmesch.github.io/math21/slides.html</a>

          <li step="2">To follow the slides as shown by the presented, insert
            the <em>query parameter</em> <b>?follow=X</b> into the URL (before
            the <b>#</b>, using the value for <b>X</b> announced by the
            presenter. This asks to allow notifications; please allow it (a
            Google Firebase mystery - this is needed even though no
            notifications will be shown).

          <li step="3">Press <b>N</b> to show speaker notes.
            
          <li step="4">May not work in your browser, your machine, or on your
            network connection. If so, please just follow on the video stream.
            
        </ul>
      </div>

      <div class="slide build-focus-visible" group="intro">
        <h1>How to ask questions</h1>

        <div>How to ask questions on VC:</div>

        <ul>
          <li step="1">TBD ...
            
        </ul>
      </div>

      <div class="slide noprint banner" group="theme1" name="theme1">
        <div>
          <b>I - Vectors and Tensors</b><br><em>Why, in software, arrays with multiple
            integer indices came to be called tensors.</em>
        </div>
      </div>
      
      <div class="slide build-visible" group="theme1">
        <h1>Vectors and Tensors - Overview</h1>
        <div>Plan for today.</div>
        <ol>
          <li step="0">Recap Axioms of Vector Space

          <li step="1">Einstein Notation

          <li step="2">Linear Independence <em>gives rise to Basis and Coordinates</em>

          <li step="3">Basis and Coordinate Transformations

          <li step="4">The Scalar Product <span step="5">$\leftarrow$ This is
              the first Tensor!</span>

          <li step="6">Tensor Coordinates and Basis Transformations
        </ol>
      </div>

      <div class="slide build-focus-visible" group="theme1-vs">
        <h1>Axioms of Vector Space</h1>
        <div>Recap what Vectors are, and Vector Spaces.</div>

        <ul>
          <li step="1"><b>Vectors</b> can be <b>added</b> to each other and
            <b>multiplied with scalar</b> numbers.
            
          <li step="2,3,4,5,6"><em>Scalar numbers</em> are elements of a <b>Field</b>,
            often
            <ul>
              <li step="3"><b>Rational Numbers</b> $Q$,
              <li step="4"><b>Real Numbers</b> $R$,
              <li step="5">or <b>Complex Numbers</b> $C$,
              <li step="6">but also <em>finite fields</em>,
                notably the <b>Galois Field</b> $GF(2)$.
            </ul>
        </ul>
      </div>

      <div class="slide build-focus-visible continued" group="theme1-vs">
        <h1>Axioms of Vector Space</h1>
        <div>Every set $V$ whose elements can be <b>added</b> to each other, and
          <b>multiplied</b> with elements from a field $F$, with the following
          properties, is a vector space.</div>

        <div step="1,2,3,4,5,6">Vector Addition:</div>
        <ol>
          <li step="2">is an operation from $V \times V$ on $V$:

            $\xvec{a} + \xvec{b} \in V$

          <li step="3">is associative:

            $(\xvec{a} + \xvec{b}) + \xvec{c} = \xvec{a} + (\xvec{b} +
            \xvec{c})$

          <li step="4">is commutative:

            $\xvec{a} + \xvec{b} = \xvec{b} + \xvec{a}$</li>

          <li step="5">has a neutral element:

            $\exists \xvec{0} \; \forall \xvec{a} \,:\, \xvec{a} + \xvec{0} =
            \xvec{a}$

          <li step="6">has an inverse:

            $\forall \xvec{a} \; \exists -\!\xvec{a} \,:\, \xvec{a} +
            (-\xvec{a}) = \xvec{0}$
        </ol>

        <div step="7,8,9,10,11,12">Scalar Multiplication:</div>
        <ol>
          <li step="8">is an operation from $F \times V$ on $V$:

            $a\xvec{a} \in V$
            
          <li step="9">is compatible with Field multiplication: $a (b \xvec{a}) = (a b) \xvec{a}$
          <li step="10">has a neutral element: $1 \xvec{a} = \xvec{a}$
          <li step="11">is distributive over vector addition: $a \xvec{a} + a \xvec{b} = a (\xvec{a} + \xvec{b})$
          <li step="12">is distributive over field addition: $a \xvec{a} + b \xvec{a} = (a + b) \xvec{a}$
        </ol>

        <div class="notes">
          <ul>
            <li>$\forall$ is implied where absent in the axioms.
            <li>technically in some terminolgy systems, scalar multiplication is
              not an operation but a function
          </ul>
        </div>
      </div>

      <div class="slide build-focus-visible" group="theme1-vs">
        <h1>Axioms of Vector Space - Examples</h1>
        <div>Two examples of what vector spaces are.</div>
        <ul>
          <li step="1">Example 1: Arrows over Rational Numbers.
            
          <li step="2">Example 2: Tuples of Real Numbers over Real Numbers.
        </ul>
      </div>

      <div class="slide build-focus" group="theme1-vs">
        <h1>Axioms of Vector Space - Example: Arrows</h1>
        <div>Arrows in the 2D plane are vectors, with their operations defined
          by Euclidean Geometry.</div>
        <div style="float:right">
          <ul>
            <li step="1,2">Vector Addition
            <li step="3,4">Scalar Multiplication - negation
            <li step="5,6">Scalar Multiplication - integers
            <li step="7,8">Scalar Multiplication - integer fractions
          </ul>
        </div>
              
        <div class="img">
          <img class="img" src="img/vectors/vector-plus.png" step="1">
          <img class="img" src="img/vectors/vector-plus-result.png" step="2">
          <img class="img" src="img/vectors/vector-neg.png" step="3">
          <img class="img" src="img/vectors/vector-neg-result.png" step="4">
          <img class="img" src="img/vectors/vector-mult.png" step="5">
          <img class="img" src="img/vectors/vector-mult-result.png" step="6">
          <img class="img" src="img/vectors/vector-frac.png" step="7">
          <img class="img" src="img/vectors/vector-frac-result.png" step="8">
        </div>
        <div class="notes">
          <ul>
            <li>All the operations are defined directly by operations in
              Euclidean geometry, not by the corresponding operations on
              coordinates.
          </ul>
        </div>
      </div>

      <div class="slide build-focus" group="theme1-vs">
        <h1>Axioms of Vector Space &mdash; Example: Tuples</h1>
        <div>Tuples of rational or real numbers are vectors.</div>
        <ul>
          <li>$(1, 2) + (1, 2) = (2, 4)$</li>
          <li>$3 \times (1, 2) = (3, 6)$</li>
        </ul>
      </div>
      
      <div class="slide build-focus-visible banner" group="theme1-vs">
        <h1>Axioms of Vector Space &mdash; Exercise</h1>
        <div>Are these two examples vector spaces?
          <ul>
            <li step="1">(a) Tuples of Rational Numbers over Real Numbers?
            <li step="2">(b) Tuples of Real Numbers over Rational Numbers?
          </ul>
        </div>
      </div>
      
      <div class="slide build-focus" group="theme1-vs">
        <h1>Axioms of Vector Space &mdash; Solution</h1>
        <div>Are these two examples vector spaces?</div>

        <ul>
          <li step="1">(a) Tuples of Rational Numbers over Real Numbers? &mdash; No,
            violates first axiom of scalar multiplication.
          <li step="2">(b) Tuples of Real Numbers over Rational Numbers? &mdash;
            Tricky! Yes, but it's infinite-dimensional. We'll see how once we
            understand linear independence ...
        </ul>
      </div>
      
      <div class="slide build-focus-visible" group="theme1-li">
        <h1>Linear Independence</h1>
        <div step="0">The existence of <b>coordinates</b> follows from the
          axioms.</div>

        <div class="notes">
          <ul>
            <li>This derivation leads to the introduction of coordinates.

            <li>It follows directly form the algebraic structure introduced by
              the axioms.
          </ul>
        </div>

        <ul>
          <li step="1">Vectors can be <b>linearly combined</b>, i.e. added
            up with weights $w_i$:

            $$\sum_{i} w_i \xvec{v}_i$$

          <li step="2">Can such combinations yield $\xvec{0}$ with coefficients
            that are not all $0$? (It's always possible with all coefficients 0,
            of course.)
            
          <li step="3">Vectors in the combination are then said to
            be <b>linearly dependent</b>.

          <li step="3">Otherwise they are <b>linearly indedendent</b>.
        </ul>

        <div class="notes">
          <ul>
            <li>The vectors $\xvec{v}_i$ in the sum are really <b>multiple
              vectors</b> (one for each index), <b>not</b> the <b>coordinates
              of one vector</b> &mdash; we get to coordinates later!
          </ul>
        </div>
      </div>

      <div class="slide build-focus-visible banner" group="theme1-li">
        <h1>Linear Independence &mdash; Exercise</h1>
        
        <div>Imagine sets of arrows that are</div>
        <ul>
          <li step="1">(a) linearly independent,
          <li step="2">(b) linearly dependent.
        </ul>
      </div>

      <div class="slide build-focus" group="theme1-li">
        <h1>Linear Independence &mdash; Solution</h1>
        
        <div>Imagine sets of arrows that are</div>

        <ul style="float:right">
          <li step="1">(a) linearly independent,
          <li step="2">(b) linearly dependent.
        </ul>

        <div class="img">
          <img class="img" src="img/vectors/vector-independent.png" step="1">
          <img class="img" src="img/vectors/vector-dependent.png" step="2">
        </div>
      </div>

      <div class="slide build-focus-visible" group="theme1-li">
        <h1>Einstein Notation</h1>
        <div>We introduce a notation for vector algebra that's very neat.</div>
        <ul>
          <li step="1">Convention:

            $$w^i \xvec{v}_i := \sum_{i} w_i \xvec{v}_i$$

          <li step="2">If an index $i$ appears in a multiplication expression both as
            upper index $w^i$ and as lower index $\xvec{v}_i$, then the sum over
            the range of the index is implied.

          <li step="3">Also for multiple indices. (Will see this for tensors.)
        </ul>
      </div>

      <div class="slide build-focus-visible continued" group="theme1-li">
        <h1>Einstein Notation</h1>
        <ul>
          <li step="0">No sum for an index on its own:
            
            $$\xvec{v}_i$$
            
            is simply a tuple of vectors.
          
            $$w^i$$
            
            is simply a tuple of weights, i.e. numbers.
          
          <li step="1">No sum for a repeated index on top or bottom:
            
            $$M_{ii}$$
            
            is the tuple of the diagonal elements of the matrix $M_{ij}$.
          </li>
        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1-li">
        <h1>Linear Independence</h1>
        <div class="notes">
          More analysis yields interesting properties of linear independence.
        </div>

        <ul>
          <li step="0">In each vector space, the maximum number of elements $\xvec{e}_i$
            in a set of linearly independent vectors is <b>fixed</b>.

          <li step="1,3">For every other vector $\xvec{v}$ added to such a set, there is a
            linear combination that yields $\xvec{0}$:

            $$v^{i}\xvec{e}_{i} + v^{0}\xvec{v} = \xvec{0}$$</li>

          <li step="2,3">Another way of saying this is that $\xvec{v}$ can be combined from
            $\xvec{e}_{i}$. With the same coefficients as above, and noticing that
            $v^{0}$ cannot be $0$:
            
            $$\xvec{v} = - \frac{v^{i}}{v^0} \xvec{e}_{i}$$
            
            (Einstein notation applies.)

          <li step="3"><b>Exercise:</b>
            <ul>
              <li>(a) why must be $v^{0} \neq 0$?
              <li>(b) Why would it be a problem otherwise?
            </ul>
        </ul>
      </div>


      <div class="slide build-visible continued" group="theme1-li">
        <h1>Linear Independence</h1>
        <div class="notes">
          One more property, and it all yields 3 important concepts.
        </div>

        <ul>
          <li step="0">Write more simply;
            
            $$\xvec{v} = v^{i} \xvec{e}_{i}$$

          <li step="1">Are these coefficients unique?

          <li step="2">It turns out yes they are!

          <li step="3">Proof follows, to show how such things work ...
        </ul>
      </div>

      <div class="slide build-focus-visible continued" group="theme1-li">
        <h1>Linear Independence</h1>
        <div step="0"><b>Proof</b> that the coefficients of any vector are unambiguous.</div>

        <ul>
          <li step="1">Assume there are two such sets of coefficients:

            $$\xvec{v} = v^{i} \xvec{e}_{i} = u^{i} \xvec{e}_{i}$$

          <li step="2">subtract one from the other:

            $$\xvec{v} - \xvec{v} = v^{i} \xvec{e}_{i} - u^{i} \xvec{e}_{i}$$

            $$\xvec{0} = (v^{i} - u^{i}) \xvec{e}_{i}$$

          <li step="3">Now remember that $\xvec{e}_i$ are linearly independent and that
            means $\xvec{0}$ can be combined <em>only</em> with <b>all</b>
            coefficients $0$.
        </ul>
      </div>

      <div class="slide build-focus-visible continued" group="theme1-li">
        <h1>Linear Independence</h1>

        <ul>
          <li step="0">Thus for all $i$:

            $$v^{i} - u^{i} = 0$$

            (No Einstein sum here.)

          <li step="1">Or:

            $$v^{i} = u^{i}$$

            QED.
            
          <li step="2">Thus, every vector in the vector space can be represented
            as a combination with unambiguous coefficients from any maximal set
            of lineary independent vectors.</li>
        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1-bt">
        <h1>Dimension, Basis, and Coordinates</h1>
        <div step="0">From the concept of Linear Indepdendece, we arrive
          at <b>3 Definitions</b>:</div>

        <ul>
          <li step="1">The maximum number of elements in a set of linearly
            independent vectors of a vector space is the <b>Dimension</b> of
            that vector space.
            
          <li step="2">Any such set itself is a <b>Basis</b> of that vector
            space.
            
          <li step="3">The coefficients in the linear combination of the basis
            vectors that yields a vector are the <b>Coordinates</b> of the
            vector in that basis.
        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1-bt">
        <h1>Coordinate Tuples vs $F^n$ Vectors</h1>
        <ul>      
          <li step="0">Once a basis is picked, every vector is represented by
            a tuple of coordinates.

          <li step="1">The tuples are elements of $F^n$, the cartesian product space of
            the scalar field.

          <li step="2">The field $F$ by its own axioms has addition and multiplication
            defined. The cartesian product naturally has addition and scalar
            multiplication &mdash; $F^n$ is a vector space too!

          <li step="3">This vector space is <b>isomorphic</b> to the original
            vector space, which often misleads us to think that
            vectors just <em>are</em> tuples of numbers.

          <li step="4">The mapping of the vectors to its coordinate tuples is called
            an <b>Isomorphism</b>. There are many such mappings, one for each
            basis of the vector space.

          <li step="5">Isomorphism is pervasive in Mathematics, and it's the
            reason we can often afford to be "sloppy" when we speak.
        </ul>
      </div>

      <div class="slide build-focus-visible banner" group="theme1-bt">
        <h1>Coordinate Tuples vs $F^n$ Vectors &mdash; Exercise</h1>
        <ul>      
          <li step="1">Define two different bases in $R^2$, and compute the
            coordinates of one vector in both bases.
        </ul>
      </div>
      
      <div class="slide build-focus-visible" group="theme1-bt">
        <h1>Coordinate Tuples vs $F^n$ Vectors &mdash; Solution</h1>
        <div step="0">Define two different bases in $R^2$, and compute the
          coordinates of one vector $\left[ \begin{array}{c} 1 \\ 1
          \end{array} \right]$ in both bases.</div>

        <ul>      
          <li style="display:flex">
            <div step="1,3">Basis 1:
              
              $\{ \left[ \begin{array}{c} 1 \\ 0 \end{array} \right],
              \left[ \begin{array}{c} 0 \\ 1 \end{array} \right]
              \}$
            </div>

            <div step="2,3">Basis 2:

              $\{ \left[ \begin{array}{c} 1 \\ 1 \end{array} \right],
              \left[ \begin{array}{c} 0 \\ 1 \end{array} \right]
              \}$
            </div>
            
          <li style="display:flex">
            <div step="4,6">Vector in Basis 1:

              $\left[ \begin{array}{c} 1 \\ 1 \end{array} \right] =
              1 \left[ \begin{array}{c} 1 \\ 0 \end{array} \right] + 
              1 \left[ \begin{array}{c} 0 \\ 1 \end{array} \right]$
            </div>
              
            <div step="5,6">Vector in Basis 2:

              $\left[ \begin{array}{c} 1 \\ 1 \end{array} \right] =
              1 \left[ \begin{array}{c} 1 \\ 1 \end{array} \right] + 
              0 \left[ \begin{array}{c} 0 \\ 1 \end{array} \right]$
            </div>
        </ul>
      </div>
      
      <div class="slide build-focus-visible" group="theme1-bt">
        <h1>Basis Transformation</h1>
        <div step="0">Let's consider <b>two</b> different bases
          $\{\xvec{a}_{i}\}$ and $\{\xvec{b}_{i^\prime}\}$ in the same vector
          space.</div>

        <ul>
          <li step="1"><b>Notation:</b> Symbols with differently primed indices
            refer to different objects. Thus $\xvec{a}_{i}$ is a different
            vector from $\xvec{a}_{i^\prime}$ even for equal values of $i$ and
            $i^\prime$.
            
          <li step="2">Every vector $\xvec{v}$ of the vector space has
            coordinates in the first base $\{\xvec{a}_{i}\}$ as well as in the
            second base $\{\xvec{b}_{i^\prime}\}$ :

            $$\xvec{v} = v^{i} \xvec{a}_{i} = v^{i^\prime} \xvec{b}_{i^\prime}$$

          <li step="3,4">The vectors ${\xvec{b}_{i^\prime}}$ of the second basis
            too have coordinates in the first base ${\xvec{a}_{i}}$. Let's call
            $T_{i^\prime}^{i}$ the coordinates of $\xvec{b}_{i^\prime}$ in the
            basis ${\xvec{a}_{i}}$:

            $$\xvec{b}_{i^\prime} = T_{i^\prime}^{i} \xvec{a}_{i}$$

          <li step="4"><b>Notation:</b> We could write $T$ as a matrix. But we
            don't, and stick to Einstein notation instead. We'll see later why
            &mdash; with tensors, will multiply such objects on "more than two
            sides".
        </ul>
      </div>

      <div class="slide build-focus-visible continued" group="theme1-bt">
        <h1>Basis Transformation</h1>
        <ul>
          <li step="0,1">Conversely, the vectors of the first basis
            $\{\xvec{a}_{i}\}$ also have coordinates in the second basis
            $\{\xvec{b}_{i^\prime}\}$ just like every vector too:

            $$\xvec{a}_{i} = T_{i}^{i^\prime} \xvec{b}_{i^\prime}$$

          <li step="1"><b>Notation:</b> the indices on $T_{i}^{i^\prime}$ and
            $T_{i^\prime}^{i}$ are different, so the note from the previous
            slide applies, and these are different objects.
        </ul>
      </div>

      <div class="slide build-focus-visible continued" group="theme1-bt">
        <h1>Basis Transformation</h1>
        <ul>
          <li step="0">So the two sets of coordinates $T_{i}^{i^\prime}$ and
            $T_{i^\prime}^{i}$ are different, but they are related, as we see
            from inserting one equation into the other:

            $$\xvec{a}_{i} = T_{i}^{i^\prime} \xvec{b}_{i^\prime}$$

            $$\xvec{a}_{i} = T_{i}^{i^\prime} T_{i^\prime}^{j} \xvec{a}_{j}$$

          <li step="1,2,3">thus:

            $$T_{i}^{i^\prime} T_{i^\prime}^{j} = \delta_{i}^{j}

            \;\;\mathrm{where}\;\;

            \delta_{i}^{j} = 1 \; (i=j), \; 0 \; (i \neq j)$$

          <li step="2">The two matrices $T_{i}^{i^\prime}$ and
            $T_{i^\prime}^{j}$ are each other's inverse.

          <li step="3"><b>Notation:</b> we don't have to care about transpose or
            ordering of factors.
        </ul>
      </div>
      
      <div class="slide build-focus-visible continued" group="theme1-bt">
        <h1>Basis Transformation</h1>
        <ul>
          <li step="0">We can ask about the relationship of the coordinates of a
            vector too:
            
            $$\xvec{v} = v^{i} \xvec{a}_{i} = v^{i^\prime} \xvec{b}_{i^\prime}$$ 

            $$\xvec{v} = v^{i} \xvec{a}_{i} = v^{i^\prime} T_{i^\prime}^{i} \xvec{a}_{i}$$ 

          <li step="1,2">thus:

            $$v^{i} = T_{i^\prime}^{i} v^{i^\prime}

            \;\; \mathrm{and\;remember} \;\;\ \xvec{a}_{i} = T_{i}^{i^\prime} \xvec{b}_{i^\prime}$$

          <li step="2">... basis vectors and coordinates transform inverse (and
            transposed) to each other.
          
          <li step="3"><b>Notation:</b> again ordering of factors is not
            important for meaning, unlike in matrix notation.
        </ul>
      </div>
          
      <div class="slide build-focus-visible" group="theme1-bt">
        <h1>Basis Transformation</h1>
        <div>We now can <b>define</b>:</div>
        <ul>
          <li step="0">$T$ is called a <b>basis transformation</b>,
          <li step="1">and correspondingly a <b>coordinate transformation</b>.
        </ul>
      </div>
      
      <div class="slide build-focus-visible banner" group="theme1-bt">
        <h1>Basis Transformation &mdash; Exercise</h1>
        <ul>
          <li>Write down the basis transformation and
            the coordinate transformation for the transition between <em>Basis
              1</em> and <em>Basis 2</em> in the previous exercise.
        </ul>
      </div>
      
      <div class="slide build-focus-visible" group="theme1-bt">
        <h1>Basis Transformation &mdash; Solution</h1>
        <div>Write down the basis transformation and the coordinate
          transformation for the transition between <em>Basis 1</em>
          and <em>Basis 2</em> in the previous exercise.</div>
        <div style="display:flex">
          <div step="1,4">Vector:

            $$\xvec{v} = \left[ \begin{array}{c} 1 \\ 1 \end{array} \right]$$


          </div>

          <div step="2,4">Basis 1:
            $$\begin{array}

            \xvec{e}_1 = \left[ \begin{array}{c} 1 \\ 0 \end{array} \right] &&

            \xvec{e}_2 = \left[ \begin{array}{c} 0 \\ 1 \end{array} \right]

            \end{array}$$
          </div>
            
          <div step="3,4">Basis 2:
            $$\begin{array}
            
            \xvec{e}_{1^\prime} = \left[ \begin{array}{c} 1 \\ 1 \end{array}
            \right] &&

            \xvec{e}_{2^\prime} = \left[ \begin{array}{c} 0 \\ 1 \end{array}
            \right]

            \end{array}$$
          </div>
        </div>
      </div>

      <div class="slide build-focus-visible continued" group="theme1-bt">
        <h1>Basis Transformation &mdash; Solution</h1>
        <div>Vector expressed in both bases:</div>
        <div style="display:flex">
          <div step="0,2">Vector in Basis 1:

            $$\xvec{v} = v^i\xvec{e}_i = 
            1 \left[ \begin{array}{c} 1 \\ 0 \end{array} \right] + 
            1 \left[ \begin{array}{c} 0 \\ 1 \end{array} \right]$$
            $$v^1 = 1, \; v^2 = 1$$
          </div>

          <div step="1,2">Vector in Basis 2:

            $$\xvec{v} = v^{i^\prime}\xvec{e}_{i^\prime} = 
            1 \left[ \begin{array}{c} 1 \\ 1 \end{array} \right] + 
            0 \left[ \begin{array}{c} 0 \\ 1 \end{array} \right]$$
            $$v^1 = 1, \; v^2 = 0$$
          </div>
        </div>
      </div>

      <div class="slide build-focus-visible continued" group="theme1-bt">
        <h1>Basis Transformation &mdash; Solution</h1>
        <div step="0">Basis transformation written down:</div>
        <div style="display:flex;align-items:center">
          <div step="1,4">
            $$\xvec{e}_{i^\prime} = T_{i^\prime}^{i} \xvec{e}_{i}$$
          </div>

          <div step="2,4">
            $$\xvec{e}_{1^\prime} = \left[ \begin{array}{c} 1 \\ 1 \end{array}
            \right] = 
            1 \left[ \begin{array}{c} 1 \\ 0 \end{array} \right] + 
            1 \left[ \begin{array}{c} 0 \\ 1 \end{array} \right] =
            1 \xvec{e}_{1} +
            1 \xvec{e}_{2}$$

            $$\xvec{e}_{2^\prime} = \left[ \begin{array}{c} 0 \\ 1 \end{array}
            \right] =
            0 \left[ \begin{array}{c} 1 \\ 0 \end{array} \right] + 
            1 \left[ \begin{array}{c} 0 \\ 1 \end{array} \right] =
            0 \xvec{e}_{1} +
            1 \xvec{e}_{2}$$
          </div>

          <div step="3,4">
            $$
            \begin{array}{c}
            T_{1^\prime}^{1} = 1 &&
            T_{1^\prime}^{2} = 1 \\
            T_{2^\prime}^{1} = 0 &&
            T_{2^\prime}^{2} = 1
            \end{array}$$
          </div>
        </div>
      </div>


      <div class="slide build-focus-visible continued" group="theme1-bt">
        <h1>Basis Transformation &mdash; Solution</h1>
        <ul>
          <li step="0">Coordinate Transformation:

            $$v^{i^\prime} = T_{i}^{i^\prime} v^{i}$$

            $$T_{i}^{i^\prime} T_{i^\prime}^{j} = \delta_i^j$$

            $$ T_{1}^{1^\prime} = ?, \;
            T_{1}^{2^\prime} = ?, \;
            T_{2}^{1^\prime} = ?, \;
            T_{2}^{2^\prime} = ? \; $$ TODO
        </ul>
      </div>
      
      <div class="slide build-focus-visible" group="theme1-sp">
        <h1>Scalar Product and Metric Tensor</h1>
        <div>Let's look at the scalar product in Vector Spaces.</div>
        <ul>
          <li step="0">The scalar product is a map from the vector space to its
            scalar field:

            $$\xvec{v} \cdot \xvec{w} = a \in F$$

          <li step="1">linear:

            $$(a \xvec{v}) \cdot \xvec{w} = a (\xvec{v} \cdot \xvec{w})$$
            
            $$(\xvec{v} + \xvec{u}) \cdot \xvec{w} = \xvec{v} \cdot \xvec{w} + \xvec{u} \cdot \xvec{w}$$
            
          <li step="2">commutative:
            $\xvec{v} \cdot \xvec{w} = \xvec{w} \cdot \xvec{v}$
            
          <li step="3">regular:
            $\forall \xvec{v} \neq \xvec{0} \; \exists \xvec{w}: \xvec{v} \cdot
            \xvec{w} \neq 0$
        </ul>

        <div class="notes">
          <ul>
            <li>For vector spaces over <b>Complex Numbers</b>, the scalar
              product is hermitean instead of commutative.
            <li>For "normal" vector spaces, the scalar product is also required
              to be positive definite.
          </ul>
        </div>
      </div>
            
      <div class="slide build-focus-visible continued" group="theme1-sp">
        <h1>Scalar Product and Metric Tensor</h1>
        <div step="0">We are on the way to define the first tensor.</div>
        <ul>
          <li step="1">The vectors can be written with coordinates in a basis $\{\xvec{e}_{i}\}$:

            $$\xvec{v} \cdot \xvec{w} = (v^{i}\xvec{e}_{i}) \cdot (w^{j} \xvec{e}_{j})$$

          <li step="2">... using the linearity of the scalar product yields:

            $$\xvec{v} \cdot \xvec{w} = v^{i} w^{j} (\xvec{e}_{i} \cdot \xvec{e}_{j})$$

          <li step="3">The scalar products of the basis vectors are just
            numbers. We call them $g$:

            $$g_{ij} := \xvec{e}_{i} \cdot \xvec{e}_{j}$$

          <li step="4">... then:

            $$\xvec{v} \cdot \xvec{w} = v^{i} w^{j} g_{ij}$$
        </ul>
      </div>

      <div class="slide build-focus-visible continued" group="theme1-sp">
        <h1>Scalar Product and Metric Tensor</h1>
        <div>
            $$\xvec{v} \cdot \xvec{w} = v^{i} w^{j} g_{ij}$$
        </div>
        <ul>
          <li step="0">For a given basis, these numbers $g_{ij}$ fully define the scalar
            product in the vector space; they are the <em>coordinates</em> of
            the bilinear map that is the scalar product.


          <li step="1">We call them coordinates because they work like coordinates of
            vectors: The object they describe is not those numbers, it's a map
            of vectors to scalar numbers, just like the vectors are not their
            coordinates. But once vectors are described by coordinates relative
            to a basis, the map is described by coordinates too
        </ul>
      </div>
      
      <div class="slide build-focus-visible banner" group="theme1-sp">
        <h1>Scalar Product and Metric Tensor &mdash; Exercise</h1>
        <div>Write down the coordinates of the scalar product for tuples from
          $R^2$ in the two bases from the previous exercise.</div>
      </div>

      <div class="slide build-focus-visible" group="theme1-sp">
        <h1>Scalar Product and Metric Tensor &mdash; Solution</h1>
        <div>Write down the coordinates of the scalar product for tuples from
          $R^2$ in the two bases from the previous exercise.</div>
        <ul>
          <li>... TODO
        </ul>
      </div>
      
      <div class="slide" group="theme1-sp">
        <h1>Scalar Product and Metric Tensor</h1>
        <div>Two interesting questions arise, both of which lead to the definition of tensors:</div>
        <ul>
          <li>(1) What are the coordinates of the scalar product in another
          basis?

          <li>(2) What are the "basis vectors" of whom the coordinates are the
            coefficients?
        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1-sp">
        <h1>Scalar Product and Metric Tensor &mdash; Coordinate Transformation</h1>
        <div step="0">What are the coordinates of the scalar product in another
          basis? Lets see ...</div>
        <ul>
          <li step="1">$\xvec{v} \cdot \xvec{w} = (v^{i}\xvec{e}_{i}) \cdot (w^{j} \xvec{e}_{j})$
            
          <li step="2">$\xvec{v} \cdot \xvec{w} = (v^{i^\prime}\xvec{e}_{i^\prime}) \cdot (w^{j^\prime} \xvec{e}_{j^\prime})$

          <li step="3">$\xvec{v} \cdot \xvec{w} = (v^{i^\prime} T_{i^\prime}^{i} \xvec{e}_{i}) \cdot (w^{j^\prime} T_{j^\prime}^{j} \xvec{e}_{j})$

          <li step="4">$\xvec{v} \cdot \xvec{w} = v^{i^\prime} w^{j^\prime} \;
            T_{i^\prime}^{i} T_{j^\prime}^{j} \; (\xvec{e}_{i} \cdot \xvec{e}_{j})$

          <li step="5">$\xvec{v} \cdot \xvec{w} = v^{i^\prime} w^{j^\prime} \;
            T_{i^\prime}^{i} T_{j^\prime}^{j} \; g_{ij}$

          <li step="6">$\xvec{v} \cdot \xvec{w} = v^{i^\prime} w^{j^\prime} \;
            g_{i^{\prime}j^{\prime}}$

          <li step="7">thus, $g_{i^{\prime}j^{\prime}} = T_{i^\prime}^{i} T_{j^\prime}^{j} \; g_{ij}$

        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1-sp">
        <h1>Tensors</h1>
        <div step="0">We can now give a definition of a Tensor, and of the Tensor
          Product Space.</div>
        <ul>
          <li step="1">A <b>Tensor</b> is any mathematical object in a vector space with
            coordinates that transform under basis transformations like a
            multilinear map.

          <li step="2">The scalar product is just one such map. There are many others.

          <li step="3">These maps can be combined and multiplied with numbers:
            
            $$(g + h)(\xvec{a}, \xvec{b}) := g(\xvec{a}, \xvec{b}) + h(\xvec{a},
            \xvec{b})$$
            
            $$(ag)(\xvec{a}, \xvec{b}) := a \cdot g(\xvec{a}, \xvec{b})$$

          <li step="4">Looking closely, they form a vector space too!

          <li step="5">The <b>Tensor Product Space</b> of $V$ is the vector space
            comprised of tensors in $V$:

            $$g,h \in V \otimes V$$

          <li step="6">Linear maps with more than two arguments are from tensor
            product spaces with more than two factors:

            $$V \otimes V \otimes V \otimes ...$$

        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1-sp">
        <h1>Scalar Product and Metric Tensor</h1>
        <div step="0">Now that we have defined Tensors, a few more <b>Definitions</b>.</div>
        <ul>
          <li step="1">A vector space over real numbers with a scalar product is
              a <b>Euclidean Vector Space</b>.
            
          <li step="2">Two vectors from a Euclidean Vector Space whose scalar product is
            $0$ are <b>Orthogonal</b>.

          <li step="3">If the scalar product is positive definite (not always the case),
            then he scalar product also gives rise to a <b>Norm</b>:

            $$|\xvec{x}| = \sqrt{\xvec{x} \cdot \xvec{x}}$$

          <li step="4">The <b>Angle</b> $\phi$ between two vectors $\xvec{x}$ and
            $\xvec{y}$ is defined by

            $$\cos \phi = \frac{\xvec{x} \cdot \xvec{y}}{\sqrt{\xvec{x} \cdot
            \xvec{x}} \sqrt{\xvec{y} \cdot \xvec{y}}}$$
        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1-sp">
        <h1>Scalar Product and Metric Tensor</h1>
        <ul>
          <li step="0">Because the scalar product defines both distance and
            direction in a Euclidean Vector Space, i.e. the <em>Metric</em>, and
            is a tensor, it's called the <b>Metric Tensor</b>.

          <li step="1">In <b>Riemann Geometry</b>, the metric tensor is given in
            every point in space, i.e. it's a <b>tensor field</b>.

          <li step="2">In <b>General Relativity</b>, the metric tensor is
            connected to the mass by a partial differential equation.
        </ul>

        <div class="notes">
          Don't confuse a tensor field with a field.
        </div>                                     
      </div>

      <div class="slide build-focus-visible" group="theme1-sp">
        <h1>Higher Order Tensors</h1>
        <ul>
          <li step="0"><b>Tensor Product Spaces</b> of $V$ arise from multilinear maps in
            the same way, e.g.:
            
            $$V \otimes V \otimes V \otimes V$$

          <li step="1">Such tensors have coordinates with as many indices:

            $$g_{ijkl}$$

          <li step="2">that transform under a basis transformation:

            $$g_{i^{\prime}j^{\prime}k^{\prime}l^{\prime}} =
            T_{i^\prime}^{i}
            T_{j^\prime}^{j}
            T_{k^\prime}^{k}
            T_{l^\prime}^{l}
            g_{ijkl}$$

          <li step="3">Natural question: What's the dimension of that space, and what
            is its basis?
        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1-sp">
        <h1>Tensor Bases</h1>
        <div step="0">We answer the second of those questions first, and the
          first in the next session ...</div>
        <ul>
          <li step="1">Given a basis ${\xvec{e}_i}$ in $V$, we define a basis in
            $V \otimes V$ as follows:

            $${\xvec{e}^i \otimes \xvec{e}^j}$$

          <li step="2">is the bilinear function of two vectors from $V$ such that

            $$(\xvec{e}^i \otimes \xvec{e}^j)(\xvec{e}_k, \xvec{e}_l) = \delta^i_k
            \delta^j_l$$

          <li step="3">then a bilinear map $g$ with coordinates $g_{ij}$ is given by

            $$g = g_{ij} \, \xvec{e}^i \otimes \xvec{e}^j$$
        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1-sp">
        <h1>Tensor Bases</h1>
        <ul>
          <li step="0">
            $g(\xvec{x}, \xvec{y}) = g_{ij} (\xvec{e}^i \otimes \xvec{e}^j)(x^k
            \xvec{e}_k, y^l \xvec{e}_l)$

          <li step="1">
            $g(\xvec{x}, \xvec{y}) = g_{ij} x^k y^l (\xvec{e}^i \otimes \xvec{e}^j)(\xvec{e}_k, \xvec{e}_l)$

          <li step="2">
            $g(\xvec{x}, \xvec{y}) = g_{ij} x^k y^l \delta^i_k \delta^j_l$

          <li step="3">
            $g(\xvec{x}, \xvec{y}) = g_{ij} x^i y^j$

          <li step="4">
            as we said earlier.
            
        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1">
        <h1>Summary</h1>
        <ul>
          <li step="0">Vectors can be added and multiplied.
          <li step="1">From that <b>follows</b> they have coordinates wrt a basis.
          <li step="2">Tensors are multilinear functions of vectors.
          <li step="3">They are themselves vectors (can be added and
            multiplied), and thus have coordinates wrt a basis.
          <li step="4">The basis and coordinates of the tensors are related to
            the basis of and coordinates of the vectors they are functions of.
          <li step="5">The coordinates of tensors are indexed by tuples of
            indexes, one from each tensor product factor. Hence the name tensor
            in software engineering for muli-dimensional arrays.
        </ul>
      </div>

      <div class="slide build-focus-visible" group="theme1">
        <h1>Conclusion</h1>
        <div step="0">Back to the question we started with: Vector and tensor
          data structures in software engineering.</div>
        <ul>
          <li step="1">Data structures that are collections indexed by integers
            are known as <b>vectors</b> and in the tensorflow library
            as <b>tensors</b>.
          <li step="2">However, if for such collections there is no addition
            defined and no multiplication by scalars, then they are not vectors
            in the linear algebra sense.
          <li step="3">They took their name because of the important property of
            vectors to be described by tuples of scalar numbers, called
            coordinates.
        </ul>
      </div>
      
      <div class="slide" group="theme1">
        <h1>Next</h1>
        <ul>
          <li>We look at the dimension of tensor product spaces, and how tensor
            products appear in Quantum Computing, but also in data structures in
            Software Engineering.
        </ul>
      </div>

      <div class="slide"></div>
    </div>

  </body>
</html>
